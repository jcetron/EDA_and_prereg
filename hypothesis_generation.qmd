---
bibliography: references.bib
---

# Hypothesis Generation {.sec-hypothesis_generation}

### Observe, describe, and build hypotheses.

Hypothesis generation is the purview of exploratory work. Hypotheses can sometimes be derived directly from highly specified theories, but in the messy world of the behavioral and social sciences, it is more common to construct hypothesis on the basis of patterns observed in exploratory datasets or selected from our experiences in the world.

<div style="float: right; position: relative; top: 0px; padding: 10px; width: 35%">
[![John Wilder Tukey](images/tukey_3.jpg)](https://csml.princeton.edu/tukey)
</div>

The principle of separating exploratory and confirmatory research into distinct lines of inquiry---crucially, inquiries conducted on *separate* datasets---derives from the original formalization of exploratory data analysis (EDA) developed by **John Tukey** in the 1970s-80s [@tukey1970; @tukey1980]. Tukey championed the value of questions that ask, "what is $X$ like?" or "what characterizes $X$?" These types of questions orient us to analyses that help us document the existence of a phenomenon, describe its features, quantify it, and summarize it.



### Descriptive analysis: charting new territory

In some cases, description and quantification of a phenomenon might itself satisfy your immediate research question. This is often the case when description alone is a considerable challenge, such as when a dataset is especially large or complex. The toolbox of descriptive analysis includes many techniques for summarizing and organizing a dataset to reveal its structure in human-readable terms. 

#### Initial description: summary statistics and distribution visualizations

Let's use an example dataset from the `datasets` package in R to illustrate some of these descriptive analyses in action. The `attitude` dataset contains aggregated data from the Chatterjee-Price attitude survey, in which clerical employees across 30 departments of a large organization were asked to evaluate their employers on a series of topics. Each row of the data frame corresponds to one department, and the values in each column are the percent of favorable responses to each question from across employees sampled in a given department. The dataset is previewed in @tbl-attitude_example_setup (I've renamed the variables based on the [documentation](https://rdrr.io/r/datasets/attitude.html) for interpretability).

```{r tbl-attitude_example_setup, message=FALSE}
# The pacman package is useful for loading and installing packages more efficiently
require(pacman)

# p_load() is a loading and installing function from pacman that we will use throughout
#  example code to load any packages used in these examples
p_load(tidyverse, ggplot2, ggdist, scales, vtable, kableExtra, DT)

# Configure some options for rendering interactive tables
options(DT.options = list(
  dom = 'tr',
  autoWidth = TRUE,
  scrollY = 400,
  scrollCollapse = TRUE,
  paging = FALSE,
  initComplete = JS(
                   "function(settings, json) {",
                      "$('table').css({'font-size': '75%'});",
                       "}"
                   ),
  buttons = list(
    
  )
  )
)

# Load attitude data
data("attitude")

# Rename using full variable names from help file
attitude_varnames_full <- c('Overall rating',
                            'Handling of employee complaints',
                            'Does not allow special privileges',
                            'Opportunity to learn',
                            'Raises based on performance',
                            'Too critical',
                            'Advancement')
colnames(attitude) <- attitude_varnames_full

# Data preview
datatable(attitude,
          width = 1000,
          caption = htmltools::tags$caption(
            style = 'caption-side: bottom; text-align: left;',
            'Direct preview of the Chatterjee-Price attitude survey data.'
            ),
          )
```

As a first step in organizing these data to understand them better, we typically compute *summary statistics*: metrics that help characterize the distributions of our variables. These are generally metrics indicating the location (mean, median, etc.) and dispersion (standard deviation, quartile range, etc.) of a given variable's distribution. @tbl-attitude_example_table is an example summary table for our employee attitude data (computed using the `sumtable()` function from the `vtable` package in R):

```{r tbl-attitude_example_table, message=FALSE}
# Construct summary table using sumtable() and render with datatable()
sumtable(attitude, out = 'return') %>%
  datatable(caption = htmltools::tags$caption(
            style = 'caption-side: bottom; text-align: left;',
            'Summary statistics table for attitude dataset by variable.'
            )
          )
```


These summary metrics are already an improvement over the raw data alone in our attempt to characterize the data, but we can do much better by adding visualizations. Even simple descriptive visualizations like the histograms shown in @fig-attitude_example_hist can help give us a better impression of each of the distributions in the data.

```{r fig-attitude_example_hist, message=FALSE, fig.id=TRUE, fig.cap="Histograms of variable distributions in attitude survey dataset."}
# Plot of all variable histograms in separate panels (facets)
ggplot(data = attitude %>%
         pivot_longer(cols = everything()) %>%
         mutate(`Survey item` = factor(name, levels = attitude_varnames_full))) +
  geom_histogram(aes(x = value, color = `Survey item`, fill = `Survey item`)) +
  xlab('Proportion of favorable responses per department (%)') +
  ggtitle('Histograms of each survey item') + 
  facet_wrap(~`Survey item`, ncol = 3) +
  theme(legend.position = 'none')
```
Histograms are great for visualizing individual distributions one at a time, but we will most likely want to compare the distributions of each survey item to one another. We can use other types of distribution visualizations such as boxplots, violin plots, or variations thereof to plot multiple distributions side by side. @fig-attitude_example_combined_dist shows an example visualizing the same survey items together on a single plot using a combination of boxplots, smoothed histograms, and raw data points. (The tools for generating these plots come from extensions of the `ggplot2` package in R, in particular the `ggdist` package.)

```{r fig-attitude_example_combined_dist, message=FALSE, fig.id=TRUE, fig.cap="Combined descriptive plot visualizing variable distributions using a combination of boxplots, smoothed histograms, and raw data points."}
# Combined plot of distributions visualized across multiple methods at once
ggplot(data = attitude %>%
         pivot_longer(cols = everything()) %>%
         mutate(`Survey item` = factor(name, levels = attitude_varnames_full)),
       aes(x = `Survey item`, y = value, fill = `Survey item`)) +
  stat_halfeye(alpha = .8, adjust = .5, justification = -.2) +
  geom_boxplot(width = .2) +
  geom_jitter(width = .05, alpha = .3) +
  ylab('Proportion of favorable responses per department (%)') +
  scale_x_discrete(labels = label_wrap(12)) + 
  ggtitle('Combined visualization plot showing distributions of each survey item') +
  theme(legend.position = 'none')
```

#### Complex description: multivariate exploratory analyses

Now that we have visualized the individual distributions of each variable and begun to compare them visually to one another, we can use more complex descriptive tools to quantify and map the relationships among the variables. For example, we might compute the relative similarities between each variable using metrics such as correlation or Euclidean distance, and then characterize and visualize those relationships using tools like cluster analysis and dimensionality-reduction techniques.

Below is an example of these more advanced exploratory methods applied our attitude data. For this example, we have invented three categories for the variables in the data: "General" for the items "Overall rating" and "Too critical", "Management" for the items "Handling of employee complaints" and "Does not allow special privileges", and "Growth" for the items "Opportunity to learn", "Raises based on performance", and "Advancement". With this category structure in our data, we can combine two techniques to see whether the multivariate relationships in the data reflect the expected category structure. The first technique is multidimensional scaling (MDS), which allows us to embed the relationships between all the variables in a 2-dimensional scatter plot for easy visualization. The second technique is a type of machine learning classification method called support vector machine (SVM) classification, which will try to place the variables into categories based on the relationships in the data. [see @mair2022 for a tutorial paper on the combined use of these two methods.]


```{r fig-attitude_example_svmmds, message=FALSE, fig.id=TRUE, fig.cap="Exploratory classification analysis plot showing multidimensional scaling (MDS) used together with support vector machine (SVM) classification on our modified attitude example data."}
# Load the smacof package which provides tools for MDS and SVM joint analysis
p_load(smacof)

# Create distance matrix for variables using Euclidean distance (default).
D <- dist(t(attitude))

# Note that transposition of the data frame (using t()) is necessary because dist()
#  compares each row to each other row, and we want to compare the variables, which
#  are set up in the columns of a data frame by default.


# Fit a 2-dimensional ordinal MDS solution using the distance matrix
mdsfit <- mds(D, ndim = 2, type = 'ordinal')

# Define categories for the variables
attitude_categories <- factor(c('General', 'Management', 'Management', 'Growth', 'Growth', 'General', 'Growth'))

# Add category information to the resultant MDS configuration in preparation for SVM categorization
attitude_mds_cat <- mdsfit$conf %>%
  as.data.frame() %>%
  mutate(Category = attitude_categories)

# Fit SVM classifier to try and categorize the variables from the MDS solution
# (we are using a bare-bones example without tuning the SVM)
svmfit <- svm(Category ~ D1 + D2, data = attitude_mds_cat, kernel = 'linear')

# Plot the joint SVM/MDS configuration plot
svm_mdsplot(mds_object = mdsfit, svm_object = svmfit, class = attitude_categories, inset = c(-.5, .5))
```

@fig-attitude_example_svmmds shows the results of the exploratory MDS/SVM analysis. The color-coded regions reflect the SVM classifier's predicted category assignments, and the point shapes represent the actual category assignments. As we can see, the data align somewhat well with the expected categories, although not perfectly---the classifier places "Overall rating" and "Opportunity to learn" incorrectly into the "Management" category, due to apparent similarities between those variables and the other "Management" variables.

Multivariate exploratory methods like these can also be used to reveal structures in the data that are not necessarily known in advance, and often in much larger datasets. In genetics research, for example, researchers will characterize cell samples based on the cells' different transcription profiles across thousands or tens of thousands of different genes, hoping to identify sensible structures through exploratory analyses. To achieve a working description of their complex sample data, biologists will use techniques like principal components analysis (PCA) to organize cell samples based on variance in their gene expression patterns, aiming to group together cells that express similar gene profiles [see @marypiper20237723318 for a basic tutorial].

![PCA in genetics research](images/pollen2014_pca_fig.png){#fig-gene_pca}

@fig-gene_pca shows an example of this analysis in action in a genetics paper from @pollen2014 (this figure is discussed as an example in [this](https://www.youtube.com/watch?v=_UVHneBUBW0) tutorial video). In this example, PCA is used to differentiate cell types based on gene transcription heterogeneity.

Methods like PCA, MDS, SVM classification, and other similar techniques are powerful descriptive methods for the current era of "big data", which continues to grow and encompass more and more scientific fields. These methods can help make complex, feature-rich data more approachable and provide a launchpad for the generation of hypotheses.

### From description to hypothesis

In many cases, exploratory description is a prerequisite step to start building up a research program so that you can design subsequent confirmatory analyses. Particularly if your research constitutes the very first inquiry into a new topic area, you might need to dedicate multiple early studies to exploration and description alone before you are ready to generate and test specific hypotheses. Before you can start worrying about statistical power, sample sizes, and *p*-values, you need to decide what question you want to ask, and how it should be formalized into a statistical model or test.

This process---of using exploration to inform hypothesis generation---is complex. And yet, we often mislead ourselves into thinking it is straightforward. To correct this misconception, we can again turn to Tukey, who articulated his concern about this issue in his piece, "We Need Both Exploratory and Confirmatory," published in *The American Statistician* in 1980. In that article, Tukey emphasized that the scientific method is not linear, but *iterative* [@tukey1980a], and illustrated this distinction using a series of diagrams (reproduced below with adjusted formatting):

> "We are, I assert, all too familiar with the following straight-line paradigm---asserted far too frequently as how science and engineering function:
>
> $(*) \; \text{question} \rightarrow \text{design} \rightarrow \text{collection} \rightarrow \text{analysis} \rightarrow \text{answer}$
>
> ...
>
> What often happens is better diagrammed thus:
>
> $(*) \; \text{idea} \rightarrow \, \circlearrowright ({\text{question} \atop \text{design}})\circlearrowright \, \rightarrow \text{collection} \rightarrow \text{analysis} \rightarrow \text{answer}$"

Tukey goes on to explain that there is an important difference between having an *idea* of a question (which we can describe in words) and having a statistically-supportable question (which we can describe in hypothesis terms). In order to obtain a research question that is ready for confirmatory analysis, we may have to repeat the exploratory process many times, refining our question and design along the way.

### Post-hoc exploratory analysis

Finally, exploratory analysis can be a *follow-up* to a completed confirmatory analysis to motivate new, subsequent lines of inquiry [see @fife2022]. It is important to always be clear about exactly *which* analyses are exploratory in this context, so as not to imply that inferential conclusions should be drawn from them. Nevertheless, researchers should not shy away from using exploratory analysis as a generative tool for guiding the long-term development of a research program.
